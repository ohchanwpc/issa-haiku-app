
from __future__ import annotations
import os, re, json, time, random, logging  # â† time, random, loggingã‚’è¿½åŠ 
from openai import OpenAI, RateLimitError, APIStatusError  # â† ä¾‹å¤–ã‚‚è¿½åŠ 

_client = None
def _get_client() -> OpenAI:
    global _client
    if _client is None:
        _client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
    return _client
# --- è¿½åŠ ï¼šæŒ‡æ•°ãƒãƒƒã‚¯ã‚ªãƒ• + ã‚¸ãƒƒã‚¿ãƒ¼ ---
def _sleep_backoff(attempt, base=0.8, cap=8.0, jitter=True):
    delay = min(cap, base * (2 ** attempt))
    if jitter:
        delay += random.random()
    logging.warning(f"[Retry] Waiting {delay:.1f} seconds before next attempt...")
    time.sleep(delay)
# -----------------------------------------
def call_gpt_haiku(payload: dict) -> dict:
    """æ–°ä½œä¿³å¥ï¼‹æ„è¨³ï¼‹å‚ç…§ç†ç”±ã‚’JSONã§è¿”ã™ã€‚"""
    client = _get_client()
    refs = payload.get('references', [])
    refs_numbered = "\n".join([f"{i+1}. {r.get('text','')} | å‡ºå…¸: {r.get('source','')}" for i, r in enumerate(refs)])

    system_prompt = """ã‚ãªãŸã¯ã€Œå°æ—ä¸€èŒ¶ Ã— æ–°ä½œä¿³å¥ Ã— å‚ç…§å¥é‹ç”¨ã€ã®å°‚é–€å®¶ã§ã™ã€‚
ä»¥ä¸‹ã®JSONã ã‘ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ï¼ˆä½™æ–‡ãƒ»è§£èª¬ãƒ»å‰ç½®ãç¦æ­¢ï¼‰ï¼š
{
  "haiku_ja": "äº”ä¸ƒäº”ã®æ–°ä½œï¼ˆæ—¥æœ¬èªï¼‰",
  "explanation_ja": "æ—¥æœ¬èªã®æ„è¨³ãƒ»èƒŒæ™¯ï¼ˆ100-200å­—ï¼‰",
  "reasons_refs_ja": "çµè«–ãƒ•ã‚¡ãƒ¼ã‚¹ãƒˆ1æ–‡ï¼‹æ”¹è¡Œï¼‹(1)(2)(3)ã‚’Markdownç®‡æ¡æ›¸ãå½¢å¼ï¼ˆ- (1) ... ã®å½¢ï¼‰ã§å‡ºåŠ›ã™ã‚‹ã€‚å½¢å¼ä¾‹:ã€ã€çµè«–ã€‘...\\n- (1) ...\\n- (2) ...\\n- (3) ...ã€"
  "references_numbered": "1. ã€‡ã€‡ | å‡ºå…¸: â–³â–³ (å¹´)\\n2. ã€‡ã€‡ | å‡ºå…¸: â–³â–³ (å¹´)\\n3. ã€‡ã€‡ | å‡ºå…¸: â–³â–³ (å¹´)"
}
å³å®ˆäº‹é …ï¼š
- å¿…ãšå‘½ã‚’æ‡¸ã‘ã¦5éŸ³ãƒ»7éŸ³ãƒ»5éŸ³ã®æ§‹æˆã«ã™ã‚‹ï¼ˆåˆè¨ˆ17ãƒ¢ãƒ¼ãƒ©ï¼‰
- 5éŸ³ 7éŸ³ 5éŸ³ã¨ã‚¹ãƒšãƒ¼ã‚¹ã§5éŸ³ 7éŸ³ 5éŸ³ã‚’åŒºåˆ‡ã£ã¦è¡¨ç¤ºã™ã‚‹
- ãƒ¢ãƒ¼ãƒ©æ•°ã¯ã€ã‚ƒã‚…ã‚‡â†’1ãƒ¢ãƒ¼ãƒ©ã€ã£â†’1ãƒ¢ãƒ¼ãƒ©ã€ã‚“â†’1ãƒ¢ãƒ¼ãƒ©ã€é•·éŸ³ï¼ˆãƒ¼ï¼‰â†’1ãƒ¢ãƒ¼ãƒ©ã¨ã—ã¦æ•°ãˆã‚‹
- è¨˜å·ãƒ»è‹±èªãƒ»ãƒ«ãƒ“ãƒ»å¥èª­ç‚¹ãƒ»è§£èª¬ã¯å‡ºåŠ›ã—ãªã„ï¼ˆä¿³å¥ã®ã¿ï¼‰
- æ–‡æœ«ã¯åè©ãƒ»ä½“è¨€æ­¢ã‚å¯ã€åŠ©è©ã§çµ‚ã‚ã£ã¦ã‚‚è‰¯ã„
-è‡ªå·±ãƒã‚§ãƒƒã‚¯ã‚’ä»¥ä¸‹3ç‚¹å®Ÿè¡Œã—ã¦ãã ã•ã„
1) ã²ã‚‰ãŒãªã«å†…éƒ¨å¤‰æ›ã—ã¦ãƒ¢ãƒ¼ãƒ©ã‚’æ•°ãˆã‚‹ï¼ˆå‡ºåŠ›ã«ã¯è¦‹ã›ãªã„ï¼‰
2) 5-7-5ã«ãªã£ã¦ã„ãªã‘ã‚Œã°å³åº§ã«è¨€ã„æ›ãˆã¦å†ç”Ÿæˆ
3) æœ€çµ‚å‡ºåŠ›ã¯ä¿³å¥3è¡Œã®ã¿
- è‡ªç„¶ã¨æ„Ÿæƒ…ã‚’ãƒ†ãƒ¼ãƒã«ã™ã‚‹
- é¸æŠã•ã‚ŒãŸæ„Ÿæƒ…ï¼ˆplutchikï¼‰ã¨æ—¥æœ¬çš„æƒ…ç·’ï¼ˆaestheticï¼‰ã‚’å¥ã®å†…å®¹ã¾ãŸã¯èªæ„Ÿã«å¿…ãšåæ˜ ã™ã‚‹ã“ã¨ã€‚   
- å¿…ãšå‚ç…§å¥ã‚’æ´»ç”¨ã—ã¦æ–°ä½œä¿³å¥ã‚’ä½œæˆã—ã¦ãã ã•ã„
- å°æ—ä¸€èŒ¶ã‚‰ã—ã•ã§ã‚ã‚‹ã€æ“¬éŸ³èªæ´»ç”¨ã«ã¤ã„ã¦ã¯å‚ç…§å¥ã‚’ã—ã¦ç”Ÿã‹ã—ã¦ãã ã•ã„ã€‚
- å°å‹•ç‰©ã¸ã®æ„›ã«ã¤ã„ã¦ã‚‚å‚ç…§å¥ã‚’ç”Ÿã‹ã—ã¦ãã ã•ã„ã€‚
- å‚ç…§å¥ã®æ–‡æœ«ã‚’ä¼¼ã›ã¦ãã ã•ã„ã€‚
- å‚ç…§å¥(1)(2)(3)ã®å…·ä½“è¦ç´ ï¼ˆèªï¼éŸ³è±¡å¾´ï¼æ§‹å›³ï¼‰ã‚’æœ€ä½1ã¤ãšã¤åæ˜ ã™ã‚‹ã“ã¨
- JSONä»¥å¤–ã¯å‡ºåŠ›ã—ãªã„ã€‚
- ã€Œç†ç”±ã€ã¯â€œå‚ç…§ä¿³å¥ã®é¸å®šç†ç”±â€ã€‚æ–‡é ­ã‚’ã€ã“ã®å¥ã¯ã€ã§å§‹ã‚ãªã„ã€‚
- ã€Œreasons_refs_jaã€ã¯å¿…ãšã€ã€çµè«–ã€‘ã€ã§å§‹ã‚ã€æ¬¡è¡Œä»¥é™ã«(1)(2)(3)ã‚’æ”¹è¡Œã§ä¸¦ã¹ã‚‹ã€‚
- å„(1)(2)(3)ã§ã¯ã€å‚ç…§å¥ã®å…·ä½“è¦ç´ ï¼ˆæ§‹é€ /ãƒªã‚ºãƒ /ãƒ†ãƒ¼ãƒ/èªæ„Ÿ ç­‰ï¼‰ã¨ã€æ–°ä½œã¸ã®å¤‰å¥ã‚’ç°¡æ½”ã«è¿°ã¹ã‚‹ã€‚
- **å‚ç…§å¥ã«æ“¬éŸ³èªï¼ˆç¹°ã‚Šè¿”ã—è¡¨ç¾ ğŸµï¼‰ãŒå«ã¾ã‚Œã‚‹å ´åˆã€ãã®ãƒªã‚ºãƒ ã‚„éŸ¿ãã‚’æ–°ä½œã§ã©ã†æ´»ã‹ã—ãŸã‹ã‚’å¿…ãšæ›¸ãã€‚**
- ã€Œæ„è¨³ã€ã¯ä¿³å¥ã®æƒ…æ™¯ã¨æ„Ÿæƒ…ã®ã¿ï¼ˆå‚ç…§å¥ã®è©±ã¯æ›¸ã‹ãªã„ï¼‰ã€‚æ—¥æœ¬çš„æƒ…ç·’ã‚’1ã¤ä»¥ä¸Šå«ã‚ã‚‹ã€‚
- å›ºæœ‰åè©ã‚„ç¾ä»£èªéå¤šã‚’é¿ã‘ã€ä¸€èŒ¶ã‚‰ã—ã„ç´ æœ´ã•ã¨ç”Ÿå‘½ã¸ã®ã¾ãªã–ã—ã‚’é‡è¦–ã€‚

"""

    user_prompt = f"""å…¥åŠ›æ¡ä»¶ï¼š
season = {payload.get('season')}
plutchik = {payload.get('plutchik')}
aesthetic = {payload.get('aesthetic')}
keyword = {payload.get('keyword')}
experience = {payload.get('experience')}

å‚ç…§ä¿³å¥ï¼ˆå¿…ãš(1)(2)(3)ã§è¨€åŠï¼‰:
{refs_numbered}
"""

    resp = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "system", "content": system_prompt},
                  {"role": "user", "content": user_prompt}],
        temperature=0.7,
        response_format={"type": "json_object"}
    )
    # --- è¿½åŠ ï¼šå†è©¦è¡Œä»˜ãAPIå‘¼ã³å‡ºã— ---
    last_err = None
    for attempt in range(max_retries):
        try:
            resp = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=0.7,
                response_format={"type": "json_object"}
            )
            break  # æˆåŠŸã—ãŸã‚‰ãƒ«ãƒ¼ãƒ—ã‚’æŠœã‘ã‚‹
        except (RateLimitError, APIStatusError) as e:
            code = getattr(e, "status_code", None)
            # 429, 500, 503 ã®ã¿å†è©¦è¡Œ
            if code in (429, 500, 503) or isinstance(e, RateLimitError):
                last_err = e
                logging.warning(f"[Attempt {attempt+1}] Rate limit or server error ({code}). Retrying...")
                if attempt < max_retries - 1:
                    _sleep_backoff(attempt)
                    continue
            raise  # ä»–ã®ã‚¨ãƒ©ãƒ¼ã¯å³åº§ã«raise
    else:
        # ãƒªãƒˆãƒ©ã‚¤å°½ããŸå ´åˆ
        raise last_err or RuntimeError("API request failed after retries")
    # --- ã“ã“ã¾ã§ ---
    content = resp.choices[0].message.content
    try:
        data = json.loads(content)
    except json.JSONDecodeError:
        s = content.strip()
        if s.startswith("```"):
            s = re.sub(r"^```[a-zA-Z]*\n?", "", s)
            s = re.sub(r"\n?```$", "", s)
        start = s.find("{"); end = s.rfind("}")
        if start != -1 and end != -1 and end > start:
            s = s[start:end+1]
        s = s.replace("â€œ", '"').replace("â€", '"').replace("â€™", "'")
        s = re.sub(r",(\s*[\]}])", r"\1", s)
        s = re.sub(r"'([A-Za-z0-9_]+)'\s*:", r'"\1":', s)
        s = re.sub(r":\s*'([^']*)'", lambda m: ':"{}"'.format(m.group(1).replace('"', '\\"')), s)
        try:
            data = json.loads(s)
        except json.JSONDecodeError:
            data = {"haiku_ja": "", "explanation_ja": "", "reasons_refs_ja": "", "references_numbered": refs_numbered}

    for k in ["haiku_ja", "explanation_ja", "reasons_refs_ja", "references_numbered"]:
        data.setdefault(k, "")
    return data

def generate_english_tweet_block(haiku_ja: str, explanation_ja: str) -> str:
    """æ—¥æœ¬èªä¿³å¥ï¼‹èª¬æ˜ã‹ã‚‰ X å‘ã‘è‹±èªãƒ–ãƒ­ãƒƒã‚¯ã‚’ç”Ÿæˆ"""
    client = _get_client()
    system_prompt = """ã‚ãªãŸã¯ã€Œä¿³å¥è‹±è¨³ Ã— Xï¼ˆTwitterï¼‰æŠ•ç¨¿æ•´å½¢ã€ã®å°‚é–€å®¶ã§ã™ã€‚
æ¬¡ã®4ãƒ–ãƒ­ãƒƒã‚¯ã ã‘ã‚’å‡ºåŠ›ï¼š
ğŸŒ¿ ä¿³å¥ï¼ˆæ—¥æœ¬èªï¼‰

{haiku_ja}

ğŸƒ Haiku (English)

{haiku_en_3lines}

âœ¨ Explanation

{explanation_en_short}

åˆ¶ç´„ï¼šåˆè¨ˆ280å­—ä»¥å†…ã€‚è‹±è¨³ã¯3è¡Œã€èª¬æ˜ã¯1-2æ–‡ã€‚çµµæ–‡å­—ã¯ğŸŒ¿ğŸƒâœ¨ã®ã¿ã€‚"""

    user_prompt = f"""ä¿³å¥ï¼ˆæ—¥æœ¬èªï¼‰:
{haiku_ja}

ä¿³å¥ã®èª¬æ˜ï¼ˆæ—¥æœ¬èªã®æ„è¨³/èƒŒæ™¯ã®è¦ç‚¹ï¼‰:
{explanation_ja}
"""
    resp = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role":"system","content":system_prompt},
                  {"role":"user","content":user_prompt}],
        temperature=0.5,
    )
    return resp.choices[0].message.content.strip()
